{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp callback.progresize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive Resizing\n",
    "> A callback to progressively resize images during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ProgressiveResize` is inspired by MosaicML's [Progressive Resizing algorithm for Composer](https://docs.mosaicml.com/en/stable/method_cards/progressive_resizing.html) which in turn was inspired by [fastai](https://github.com/fastai/fastbook/blob/780b76bef3127ce5b64f8230fce60e915a7e0735/07_sizing_and_tta.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from fastcore.basics import detuplify\n",
    "from fastcore.transform import Pipeline, Transform\n",
    "\n",
    "from fastai.callback.core import Callback\n",
    "from fastai.callback.fp16 import MixedPrecision\n",
    "from fastai.learner import _cast_tensor\n",
    "from fastai.vision.augment import AffineCoordTfm, RandomResizedCropGPU\n",
    "\n",
    "from fastxtend.callback.cutmixup import CutMixUpAugment\n",
    "from fastxtend.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "_resize_augs = (AffineCoordTfm, RandomResizedCropGPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "def _to_size(t:Tensor):\n",
    "    \"Convert Tensor to size compatible values\"\n",
    "    if sum(t.shape)==2: return tuple(t.tolist())\n",
    "    else:               return tuple(t.item(),t.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "def _num_steps(input_size, current_size, min_increase):\n",
    "    \"Convert Tensor to size compatible values\"\n",
    "    steps = (input_size - current_size) / min_increase\n",
    "    if sum(steps.shape)==2: \n",
    "        steps = steps[0].item()\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exporti\n",
    "def _evenly_divisible(input_size, current_size, min_increase, steps):\n",
    "    min_increase = tensor(min_increase)\n",
    "    return (((input_size-current_size) % min_increase).sum() == 0) and (((input_size-current_size) - (min_increase*steps)).sum() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ProgSizeMode(Enum):\n",
    "    \"Delete batch after resize to assist with PyTorch memory management\"\n",
    "    Auto = 'auto'\n",
    "    Strict = 'strict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class ProgressiveResize(Callback):\n",
    "    order = MixedPrecision.order+1 # Needs to run after MixedPrecision\n",
    "    \"Progressively increase the size of input images during training. Final image size is the valid image size or `input_size`.\"\n",
    "    def __init__(self,\n",
    "        initial_size:float|tuple[int,int]=0.5, # Staring size to increase from. Image shape must be square\n",
    "        start:Number=0.5, # Earliest upsizing epoch in percent of training time or epoch (index 0)\n",
    "        finish:Number=0.75, # Last upsizing epoch in percent of training time or epoch (index 0)\n",
    "        min_increase:int=4, # Minimum increase per upsizing epoch\n",
    "        size_mode:ProgSizeMode=ProgSizeMode.Auto, # Automatically determine the resizing schedule or manually set `start` and `finish`\n",
    "        resize_mode:str='bilinear', # PyTorch interpolate mode string for progressive resizing\n",
    "        add_resize:bool=False, # Add a seperate resize step. Use for non-fastai DataLoaders or DataLoaders without batch transforms\n",
    "        resize_valid:bool=True, # Apply progressive resizing to valid dataset\n",
    "        input_size:tuple[int,int]|None=None, # Final image size. Set if using a non-fastai DataLoaders.\n",
    "        empty_cache:bool=False, # Call `torch.cuda.empty_cache()` before a resizing epoch. May prevent cuda & magma errors. Don't use with multiple GPUs.\n",
    "        verbose:str=True, # Print a summary of the progressive resizing schedule\n",
    "        logger_callback:str='wandb', # Log report and samples/second to `logger_callback` using `Callback.name` if avalible\n",
    "    ):\n",
    "        store_attr()\n",
    "        self.run_valid = resize_valid\n",
    "\n",
    "    def before_fit(self):\n",
    "        \"Sets up Progressive Resizing\"\n",
    "        if hasattr(self.learn, 'lr_finder') and not hasattr(self, \"gather_preds\"):\n",
    "            self.run = False\n",
    "            return\n",
    "\n",
    "        self._resize, self.remove_resize, self.null_resize, self.remove_cutmix = [], True, True, False\n",
    "        self._log_after_resize = getattr(self, f'_{self.logger_callback}_log_after_resize', noop)\n",
    "        self.has_logger = hasattr(self.learn, self.logger_callback) and self._log_after_resize != noop\n",
    "        self.min_increase = tensor(self.min_increase)\n",
    "\n",
    "        # Dry run at full resolution to pre-allocate memory\n",
    "        # See https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html#pre-allocate-memory-in-case-of-variable-input-length\n",
    "        try:\n",
    "            states = get_random_states()\n",
    "            path = self.path/self.model_dir\n",
    "            path.mkdir(parents=True, exist_ok=True)\n",
    "            tmp_d = TemporaryDirectory(dir=path)\n",
    "            tmp_p = Path(tmp_d.name).stem\n",
    "            self.learn.save(f'{tmp_p}/_tmp')\n",
    "\n",
    "            b = self.dls.valid.one_batch()\n",
    "            i = getattr(self.dls, 'n_inp', 1 if len(b)==1 else len(b)-1)\n",
    "            self.learn.xb, self.learn.yb = b[:i],b[i:]\n",
    "\n",
    "            if hasattr(self.learn, 'mixed_precision'):\n",
    "                self.learn.mixed_precision.autocast.__enter__()\n",
    "\n",
    "            self.learn.pred = self.learn.model(*_cast_tensor(self.learn.xb))\n",
    "            self.learn.loss = self.learn.loss_func(self.learn.pred, *_cast_tensor(self.learn.yb))\n",
    "\n",
    "            if hasattr(self.learn, 'mixed_precision'):\n",
    "                self.learn.mixed_precision.autocast.__exit__(None, None, None)\n",
    "\n",
    "            self.learn.loss.backward()\n",
    "            self.learn.opt.zero_grad()\n",
    "\n",
    "        finally:\n",
    "            self.learn.load(f'{tmp_p}/_tmp', with_opt=True)\n",
    "            tmp_d.cleanup()\n",
    "            set_random_states(**states)\n",
    "\n",
    "        # Try to automatically determine the input size\n",
    "        try:\n",
    "            for n in range(i):\n",
    "                x = detuplify(self.learn.xb[n])\n",
    "                if isinstance(x, TensorImageBase):\n",
    "                    self.input_size = x.shape[-2:]\n",
    "        finally:\n",
    "            if self.input_size is None: \n",
    "                raise ValueError(f'Could not determine input size. Set `input_size`: {self.input_size}')\n",
    "            self.input_size = tensor(self.input_size)\n",
    "            if self.input_size[0] != self.input_size[1]:\n",
    "                raise ValueError(f'`ProgressiveResize` does not support non-square images: `input_size` = {self.input_size.tolist()}')\n",
    "            if self.input_size[0] % 2 != 0:\n",
    "                 raise ValueError(f\"Input shape must be even: {self.input_size}\")\n",
    "            assert self.min_increase.item() % 2 == 0, f\"Minimum increase must be even: {self.min_increase}\"\n",
    "\n",
    "        # Set the initial size\n",
    "        if isinstance(self.initial_size, float): \n",
    "            self.current_size = (tensor(self.initial_size) * self.input_size).int()\n",
    "        elif isinstance(self.initial_size, tuple): \n",
    "            self.current_size = tensor(self.initial_size)\n",
    "\n",
    "        start_epoch  = int(self.n_epoch*self.start)  if self.start < 1  else self.start\n",
    "        finish_epoch = int(self.n_epoch*self.finish) if self.finish < 1 else self.finish\n",
    "        max_steps = finish_epoch - start_epoch \n",
    "\n",
    "        # Automatically determine the number of steps, increasing `min_increase` as needed\n",
    "        if self.size_mode == ProgSizeMode.Auto:\n",
    "            count = 10000 # prevent infinite loop\n",
    "            steps = _num_steps(self.input_size, self.current_size, self.min_increase)\n",
    "            while ((steps > max_steps) or not _evenly_divisible(self.input_size, self.current_size, self.min_increase, steps)) and count > 0:\n",
    "                self.min_increase += 2\n",
    "                steps = _num_steps(self.input_size, self.current_size, self.min_increase)\n",
    "                count -= 1\n",
    "        n_steps = _num_steps(self.input_size, self.current_size, self.min_increase)\n",
    "\n",
    "        # Double check that the number of resize steps works\n",
    "        if (n_steps > max_steps) or ((max_steps % n_steps != 0) and self.size_mode != ProgSizeMode.Auto):\n",
    "            raise ValueError(f'invalid number of steps {n_steps}')\n",
    "\n",
    "        # Double check that the step size works\n",
    "        if not _evenly_divisible(self.input_size, self.current_size, self.min_increase, n_steps):\n",
    "            raise ValueError(f'Resize amount {self.input_size-self.current_size} not evenly divisible by `min_increase` {self.min_increase}')\n",
    "\n",
    "        # Set when progressive resizing steps are applied\n",
    "        step_size = int(max_steps / n_steps)\n",
    "        start_epoch = finish_epoch - ((self.input_size-self.current_size) / self.min_increase)*step_size\n",
    "        if isinstance(start_epoch, torch.Tensor):\n",
    "            if sum(start_epoch.shape)==2: start_epoch = int(start_epoch[0].item())\n",
    "            else:                         start_epoch = int(start_epoch.item())\n",
    "        self.step_epochs = [i for i in range(start_epoch+step_size, finish_epoch+step_size, step_size)]\n",
    "\n",
    "        if self.verbose:\n",
    "            msg = f'Progressively increase the initial image size of {self.current_size.tolist()} by {self.min_increase} '\\\n",
    "                  f'pixels every {step_size} epoch{\"s\" if step_size > 1 else \"\"} for {len(self.step_epochs)} resizes.\\nStarting '\\\n",
    "                  f'at epoch {start_epoch+step_size} and finishing at epoch {finish_epoch} for a final training size of '\\\n",
    "                  f'{(self.current_size+(len(self.step_epochs))*self.min_increase).tolist()}.'\n",
    "            print(msg)\n",
    "\n",
    "        # If `add_resize`, add a seperate resize\n",
    "        if self.add_resize:\n",
    "            self._resize_pipe = Pipeline(AffineCoordTfm(size=_to_size(self.current_size), mode=self.resize_mode))\n",
    "            self._resize.append(self._resize_pipe[0])\n",
    "            self.remove_resize = True\n",
    "        else:\n",
    "            if hasattr(self.learn, 'cutmixupaugment'):\n",
    "                # Modify the `CutMixUpAugment` augmentation pipeline \n",
    "                self._process_pipeline(self.learn.cutmixupaugment._orig_pipe, False)\n",
    "\n",
    "                # If `CutMixUpAugment` has an Affine Transform for Augmentations then use it\n",
    "                if len(self._resize) > 0:\n",
    "                    # Check for pre-mixup augment pipeline and modify it\n",
    "                    if self.learn.cutmixupaugment._docutmixaug:\n",
    "                        self._process_pipeline(self.learn.cutmixupaugment._cutmixaugs_pipe, False)\n",
    "                    else:\n",
    "                        # There isn't one, then add it a pre-mixup augment pipeline for resizing\n",
    "                        self.learn.cutmixupaugment._cutmixaugs_pipe = Pipeline(AffineCoordTfm(size=_to_size(self.current_size)))\n",
    "                        self.learn.cutmixupaugment._docutmixaug = True\n",
    "                        self._resize.append(self.learn.cutmixupaugment._cutmixaugs_pipe[0])\n",
    "                        self.remove_cutmix, self.remove_resize = True, True\n",
    "\n",
    "            else:\n",
    "                # If no `CutMixUpAugment` check the train dataloader pipeline for Affine Transforms\n",
    "                self._process_pipeline(self.dls.train.after_batch.fs, False)\n",
    "\n",
    "            # If `resize_valid` check the valid dataloader pipeline for Affine Transforms\n",
    "            if self.resize_valid:\n",
    "                self._process_pipeline(self.dls.valid.after_batch.fs, False)\n",
    "\n",
    "            # If no there are no detected resizes add a resize transform pipeline\n",
    "            if len(self._resize) == 0:\n",
    "                self.add_resize = True\n",
    "                self._resize_pipe = Pipeline(AffineCoordTfm(size=_to_size(self.current_size)))\n",
    "                self._resize.append(self._resize_pipe[0])\n",
    "                self.remove_resize = True\n",
    "\n",
    "        # Set created or detected resize to the first size and store original interpolation\n",
    "        self._orig_modes = []\n",
    "        for resize in self._resize:\n",
    "            resize.size = _to_size(self.current_size)\n",
    "            self._orig_modes.append(resize.mode)\n",
    "            resize.mode = self.resize_mode\n",
    "\n",
    "    def before_batch(self):\n",
    "        \"Applies optional additional resize\"\n",
    "        if self.add_resize:\n",
    "            self.learn.xb = self._resize_pipe(self.xb)\n",
    "            # self.learn.yb = self._resize_pipe(self.yb) TODO this wasn't working\n",
    "        \n",
    "    def before_train(self):\n",
    "        \"Increases the image size before the training epoch\"\n",
    "        if len(self.step_epochs)> 0 and self.epoch >= self.step_epochs[0]:\n",
    "            _ = self.step_epochs.pop(0)\n",
    "            self.current_size += self.min_increase\n",
    "        \n",
    "            for i, resize in enumerate(self._resize):\n",
    "                if (self.current_size < self.input_size).all():\n",
    "                    resize.size = _to_size(self.current_size)\n",
    "                else:\n",
    "                    # Reset everything after progressive resizing is done\n",
    "                    if self.null_resize: \n",
    "                        resize.size = None\n",
    "                    elif self.remove_resize:\n",
    "                        if self.remove_cutmix:\n",
    "                            self.learn.cutmixupaugment._cutmixaugs_pipe = Pipeline([])\n",
    "                            self.learn.cutmixupaugment._docutmixaug = False\n",
    "                        else:\n",
    "                            self._resize_pipe = Pipeline([])\n",
    "                            self.add_resize = False\n",
    "                    else:\n",
    "                        resize.size = _to_size(self.current_size)\n",
    "                        resize.mode = self._orig_modes[i]\n",
    "        if self.has_logger: self._log_after_resize()\n",
    "\n",
    "    def after_epoch(self):\n",
    "        'Calls `torch.cuda.empty_cache()` if `empty_cache=True` before a resizing epoch. May slightly increase single GPU training speed. Do not use with multiple GPUs.'\n",
    "        if self.empty_cache and len(self.step_epochs) > 0 and self.epoch+1 >= self.step_epochs[0]:\n",
    "            del self.learn.xb\n",
    "            del self.learn.yb\n",
    "            del self.learn.pred\n",
    "            torch.cuda.empty_cache()\n",
    "        if self.has_logger: self._log_after_resize(step=0)\n",
    "\n",
    "    def _process_pipeline(self, pipe, remove_resize=False, null_resize=None):\n",
    "        \"Helper method for processing augmentation pipelines\"\n",
    "        for p in pipe:\n",
    "            if isinstance(p, _resize_augs):\n",
    "                self._resize.append(p)\n",
    "                if null_resize is None:\n",
    "                    self.null_resize = self.null_resize and p.size is None\n",
    "                else:\n",
    "                    self.null_resize = null_resize\n",
    "        self.remove_resize = remove_resize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progressive resizing initially trains on downsampled images then gradually increases the image size over multiple epochs to the full size for the rest of training. This can significantly reduce training time at the expense of lower model performance. The model must be cababily of variable image sizes.\n",
    "\n",
    "> Important: <code>ProgressiveResize</code> should increase GPU throughput which may cause other parts of the training pipeline may become a bottlneck. An easy way to increase fastai dataloader throughput is by [replacing pillow with pillow-simd](https://docs.fast.ai/dev/performance.html#pillow-simd).\n",
    "\n",
    "When testing Composer's [Progressive Resizing](https://docs.mosaicml.com/en/stable/method_cards/progressive_resizing.html) callback MosiacML [found]( https://docs.mosaicml.com/en/stable/method_cards/progressive_resizing.html#technical-details):\n",
    "\n",
    "> In our experiments, Progressive Resizing improves the attainable tradeoffs between training speed and the final quality of the trained model. In some cases, it leads to slightly lower quality than the original model for the same number of training steps. However, Progressive Resizing increases training speed so much (via improved throughput during the early part of training) that it is possible to train for more steps, recover accuracy, and still complete training in less time.\n",
    "\n",
    "`ProgressiveResize` modifies the fastai batch augmentations pipeline to change the batch resize size. If there isn't a batch augmentation, `ProgressiveResize` temporarily adds one. This occurs at the beginning of an epoch, as resizing in the middle of an epoch exhibited stability issues. It is also compatible with `CutMixUpAugment`.\n",
    "\n",
    "> Note: If training with `ProgressiveResize` results in CUDA or Magma errors, try setting `empty_cache=True` which will call `torch.cuda.empty_cache()` before a resizing epoch. This may interfere with training multiple models on multi-GPU systems.\n",
    "\n",
    "Progressive resizing appears to work best when the resize steps are small (16 or less pixels) and spread out over multiple epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastxtend.test_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# modified from https://github.com/thomasbrandon/mish-cuda/blob/master/test/perftest.py\n",
    "\n",
    "import numpy as np\n",
    "def scale_time(val:float, spec:str=\"#0.4G\"):\n",
    "    \"Scale fractional second `time` values and return formatted to `spec`\"\n",
    "    if val == 0: return '-'\n",
    "    PREFIXES = np.array([c for c in u\"yzafpnÂµm kMGTPEZY\"])\n",
    "    exp = np.int8(np.log10(np.abs(val)) // 3 * 3 * np.sign(val))\n",
    "    val /= 10.**exp\n",
    "    prefix = PREFIXES[exp//3 + len(PREFIXES)//2]\n",
    "    return f\"{val:{spec}}{prefix}s\"\n",
    "\n",
    "class SyncthProgResizeTest(Callback):\n",
    "    order = ProgressiveResize.order+1\n",
    "    def __init__(self, input_size, start_size, increase, step_size, first_epoch, last_epoch, total_resizes):\n",
    "        store_attr()\n",
    "\n",
    "    def before_fit(self):\n",
    "        prog = self.learn.progressive_resize\n",
    "        if isinstance(self.start_size, tuple):\n",
    "            assert torch.equal(prog.current_size, tensor(self.start_size).int())\n",
    "        else:\n",
    "            assert torch.equal(prog.current_size, tensor([self.start_size,self.start_size]).int())\n",
    "        assert prog.min_increase==self.increase\n",
    "        assert prog.step_epochs[1]-prog.step_epochs[0]==self.step_size\n",
    "        assert prog.step_epochs[0]==self.first_epoch\n",
    "        assert prog.step_epochs[-1]==self.last_epoch\n",
    "        assert len(prog.step_epochs)==self.total_resizes\n",
    "        size = self.start_size\n",
    "        for i in prog.step_epochs:\n",
    "            size += self.increase\n",
    "        assert size==self.input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [128, 128] by 32 pixels every 1 epoch for 4 resizes.\n",
      "Starting at epoch 12 and finishing at epoch 15 for a final training size of [256, 256].\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "test = SyncthProgResizeTest(input_size=256, start_size=128, increase=32, step_size=1, first_epoch=12, last_epoch=15, total_resizes=4)\n",
    "learn = synth_learner(cbs=[ProgressiveResize(input_size=[256,256]), test])\n",
    "learn('after_create')\n",
    "learn.create_opt()\n",
    "learn.n_epoch=20\n",
    "learn('before_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [128, 128] by 8 pixels every 1 epoch for 16 resizes.\n",
      "Starting at epoch 34 and finishing at epoch 49 for a final training size of [256, 256].\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "test = SyncthProgResizeTest(input_size=256, start_size=128, increase=8, step_size=1, first_epoch=34, last_epoch=49, total_resizes=16)\n",
    "learn = synth_learner(cbs=[ProgressiveResize(input_size=[256,256]), test])\n",
    "learn('after_create')\n",
    "learn.create_opt()\n",
    "learn.n_epoch=66\n",
    "learn('before_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [192, 192] by 6 pixels every 2 epochs for 32 resizes.\n",
      "Starting at epoch 163 and finishing at epoch 225 for a final training size of [384, 384].\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "test = SyncthProgResizeTest(input_size=384, start_size=192, increase=6, step_size=2, first_epoch=163, last_epoch=225, total_resizes=32)\n",
    "learn = synth_learner(cbs=[ProgressiveResize(input_size=[384,384], min_increase=6), test])\n",
    "learn('after_create')\n",
    "learn.create_opt()\n",
    "learn.n_epoch=300\n",
    "learn('before_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [192, 192] by 8 pixels every 3 epochs for 24 resizes.\n",
      "Starting at epoch 156 and finishing at epoch 225 for a final training size of [384, 384].\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "test = SyncthProgResizeTest(input_size=384, start_size=192, increase=8, step_size=3, first_epoch=156, last_epoch=225, total_resizes=24)\n",
    "learn = synth_learner(cbs=[ProgressiveResize(input_size=[384,384], min_increase=8), test])\n",
    "learn('after_create')\n",
    "learn.create_opt()\n",
    "learn.n_epoch=300\n",
    "learn('before_fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, I train a ResNet50 on a SageMaker Studio Lab Tesla T4 instance for 20 epochs on Imagenette at an image size of 224 pixels. Even in this 20 epoch example, `ProgressiveResize` yields training time savings compared to a full sized run. ~14 minutes to ~10.5 minutes with an accuracy dropoff from ~86.2% to ~85.6%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "import time\n",
    "\n",
    "from fastcore.basics import num_cpus\n",
    "\n",
    "from fastai.data.external import URLs, untar_data\n",
    "from fastai.data.block import DataBlock, CategoryBlock\n",
    "from fastai.data.transforms import GrandparentSplitter, get_image_files, parent_label, Normalize\n",
    "from fastai.learner import Learner\n",
    "from fastai.vision.augment import Resize, aug_transforms\n",
    "from fastai.vision.core import imagenet_stats\n",
    "from fastai.vision.data import ImageBlock\n",
    "from fastai.vision.models import resnet50\n",
    "from fastxtend.callback.channelslast import *\n",
    "from fastxtend.metrics import *\n",
    "from fastxtend.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "free_gpu_memory(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "class ProgressiveResizeTest(Callback):\n",
    "    run_valid, order = True, ProgressiveResize.order+1\n",
    "    \n",
    "    def before_fit(self):\n",
    "        self.progsize = self.learn.progressive_resize.current_size\n",
    "\n",
    "    def before_batch(self):\n",
    "        assert L(self.x.shape[-2:]) == L(self.progsize.tolist())\n",
    "            \n",
    "    def after_batch(self):\n",
    "        self.progsize = self.learn.progressive_resize.current_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively increase the initial image size of [112, 112] by 14 pixels every 1 epoch for 8 resizes.\n",
      "Starting at epoch 9 and finishing at epoch 16 for a final training size of [224, 224].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.122014</td>\n",
       "      <td>2.182029</td>\n",
       "      <td>0.227516</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.905108</td>\n",
       "      <td>2.192691</td>\n",
       "      <td>0.363057</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.690208</td>\n",
       "      <td>1.839630</td>\n",
       "      <td>0.487389</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.433910</td>\n",
       "      <td>1.606834</td>\n",
       "      <td>0.480764</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.286285</td>\n",
       "      <td>3.116283</td>\n",
       "      <td>0.494522</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.200042</td>\n",
       "      <td>1.254510</td>\n",
       "      <td>0.626242</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.105527</td>\n",
       "      <td>1.396334</td>\n",
       "      <td>0.572484</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.106385</td>\n",
       "      <td>1.339236</td>\n",
       "      <td>0.564586</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.982895</td>\n",
       "      <td>0.885877</td>\n",
       "      <td>0.723822</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.953809</td>\n",
       "      <td>1.116866</td>\n",
       "      <td>0.637197</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.843665</td>\n",
       "      <td>1.307829</td>\n",
       "      <td>0.638471</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.802480</td>\n",
       "      <td>1.135976</td>\n",
       "      <td>0.643822</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.725916</td>\n",
       "      <td>0.727306</td>\n",
       "      <td>0.765350</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.624359</td>\n",
       "      <td>0.705979</td>\n",
       "      <td>0.771465</td>\n",
       "      <td>00:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.564622</td>\n",
       "      <td>0.571569</td>\n",
       "      <td>0.814267</td>\n",
       "      <td>00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.488334</td>\n",
       "      <td>0.559648</td>\n",
       "      <td>0.821911</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.438291</td>\n",
       "      <td>0.491797</td>\n",
       "      <td>0.842548</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.381706</td>\n",
       "      <td>0.471103</td>\n",
       "      <td>0.853503</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.343013</td>\n",
       "      <td>0.457413</td>\n",
       "      <td>0.855032</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.308196</td>\n",
       "      <td>0.461995</td>\n",
       "      <td>0.855796</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 629.7 s\n"
     ]
    }
   ],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_320)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(224),\n",
    "                        batch_tfms=[*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "    dls =  dblock.dataloaders(imagenette, bs=128, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    cbs = [ProgressiveResize(start=0.2, finish=0.8), ProgressiveResizeTest]\n",
    "    learn = Learner(dls, resnet50(num_classes=dls.c), metrics=Accuracy(), cbs=cbs).to_channelslast()\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    learn.fit_one_cycle(20, 3e-3)\n",
    "    total = time.perf_counter() - start\n",
    "    print(f'Total training time: {scale_time(total)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|slow\n",
    "#|cuda\n",
    "free_gpu_memory(learn, dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.016391</td>\n",
       "      <td>2.256088</td>\n",
       "      <td>0.241274</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.769153</td>\n",
       "      <td>3.686334</td>\n",
       "      <td>0.311083</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.529073</td>\n",
       "      <td>1.638564</td>\n",
       "      <td>0.471847</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.348534</td>\n",
       "      <td>1.439297</td>\n",
       "      <td>0.554650</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.181351</td>\n",
       "      <td>1.534368</td>\n",
       "      <td>0.530446</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.127666</td>\n",
       "      <td>1.914330</td>\n",
       "      <td>0.532994</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.025626</td>\n",
       "      <td>3.243782</td>\n",
       "      <td>0.461911</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.951557</td>\n",
       "      <td>1.247780</td>\n",
       "      <td>0.625987</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.887196</td>\n",
       "      <td>0.973012</td>\n",
       "      <td>0.694777</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.855779</td>\n",
       "      <td>1.063800</td>\n",
       "      <td>0.663694</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.939424</td>\n",
       "      <td>0.721019</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.734812</td>\n",
       "      <td>0.883735</td>\n",
       "      <td>0.711083</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.650073</td>\n",
       "      <td>0.719170</td>\n",
       "      <td>0.777580</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.573434</td>\n",
       "      <td>0.835425</td>\n",
       "      <td>0.745732</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.527194</td>\n",
       "      <td>0.652105</td>\n",
       "      <td>0.806115</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.460990</td>\n",
       "      <td>0.541590</td>\n",
       "      <td>0.826752</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.402692</td>\n",
       "      <td>0.477356</td>\n",
       "      <td>0.851465</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.361319</td>\n",
       "      <td>0.463299</td>\n",
       "      <td>0.861146</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.321333</td>\n",
       "      <td>0.447778</td>\n",
       "      <td>0.863949</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.293849</td>\n",
       "      <td>0.447774</td>\n",
       "      <td>0.862420</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 840.6 s\n"
     ]
    }
   ],
   "source": [
    "#|slow\n",
    "#|cuda\n",
    "imagenette = untar_data(URLs.IMAGENETTE_320)\n",
    "\n",
    "with less_random():\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                        splitter=GrandparentSplitter(valid_name='val'),\n",
    "                        get_items=get_image_files, get_y=parent_label,\n",
    "                        item_tfms=Resize(224),\n",
    "                        batch_tfms=[*aug_transforms(),Normalize.from_stats(*imagenet_stats)])\n",
    "    dls =  dblock.dataloaders(imagenette, bs=128, num_workers=num_cpus(), pin_memory=True)\n",
    "\n",
    "    learn = Learner(dls, resnet50(num_classes=dls.c), metrics=Accuracy()).to_channelslast()\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    learn.fit_one_cycle(20, 3e-3)\n",
    "    total = time.perf_counter() - start\n",
    "    print(f'Total training time: {scale_time(total)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progressive Resizing Wandb Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "try:\n",
    "    import wandb\n",
    "\n",
    "    @patch\n",
    "    def _wandb_log_after_resize(self:ProgressiveResize):\n",
    "        size = _to_size(self.current_size, step=1)\n",
    "        wandb.log({'progressive_resize_size': size[0]}, self.learn.wandb._wandb_step+step)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend to other Loggers\n",
    "\n",
    "To extend to new loggers, follow the Weights & Biases code above and create patches for `ProgressiveResize` to add a `_{Callback.name}_log_after_resize`, where `Callback.name` is the [name of the logger callback](https://docs.fast.ai/callback.core.html#Callback.name).\n",
    "\n",
    "Then to use, pass `logger_callback='{Callback.name}'` to `Learner.profile()`. \n",
    "\n",
    "`ProgressiveResize` sets its `_log_after_resize` method to `f'_{self.logger_callback}_log_after_resize'`, which should match the patched method.\n",
    "\n",
    "```python\n",
    "self._log_after_resize = getattr(self, f'_{self.logger_callback}_log_after_resize', noop)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
